<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Publications | Tuan-Duy H. Nguyen</title><link>https://duynht.github.io/publication/</link><atom:link href="https://duynht.github.io/publication/index.xml" rel="self" type="application/rss+xml"/><description>Publications</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 18 Sep 2022 00:00:00 +0000</lastBuildDate><image><url>https://duynht.github.io/media/icon_hua19636e4b669d866f23e0e3bea925e22_51837_512x512_fill_lanczos_center_3.png</url><title>Publications</title><link>https://duynht.github.io/publication/</link></image><item><title>A Vietnamese-English Neural Machine Translation System (INTERSPEECH 2022 Show &amp; Tell)</title><link>https://duynht.github.io/publication/vi_translation/</link><pubDate>Sun, 18 Sep 2022 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/vi_translation/</guid><description>&lt;p>Pre-trained VinAI Translate models vinai/vinai-translate-vi2en and vinai/vinai-translate-en2vi are state-of-the-art text translation models for Vietnamese-to-English and English-to-Vietnamese, respectively. Our demonstration system VinAI Translate employing these pre-trained models is available at: &lt;a href="https://vinai-translate.vinai.io" target="_blank" rel="noopener">https://vinai-translate.vinai.io&lt;/a>.&lt;/p></description></item><item><title>Robust Bayesian Recourse (UAI 2022)</title><link>https://duynht.github.io/publication/robust_bayesian_recourse/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/robust_bayesian_recourse/</guid><description>&lt;p>We introduce a model-agnostic recourse that minimizes the posterior probability odds ratio along its min-max robust counterpart with the goal of hedging against future changes in the machine learning model parameters. Robust Bayesian Recourse explicitly takes into account possible perturbations of the data in a Gaussian mixture ambiguity set prescribed using the optimal transport (Wasserstein) distance.&lt;/p>
&lt;video controls >
&lt;source src="https://duynht.github.io/publication/robust_bayesian_recourse/featured.mp4" type="video/mp4">
&lt;/video></description></item><item><title>Vietnamese Speech-based Question Answering over Car Manuals (DCAI@NeurIPS2021 and IUI 2022)</title><link>https://duynht.github.io/publication/vi_carqa/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/vi_carqa/</guid><description>&lt;p>We develop QA-CarManual as a lightweight, real-time and interactive system that integrates state-of-the-art technologies in language and speech processing to (i) understand and interact with users via speech commands and (ii) automatically query the knowledge base and return answers in both forms of text and speech as well as visualization.&lt;/p>
&lt;video controls >
&lt;source src="https://duynht.github.io/publication/vi_carqa/featured.mp4" type="video/mp4">
&lt;/video></description></item><item><title>SHREC 2021: Retrieval and classification of protein surfaces equipped with physical and chemical properties (CAG Vol. 99)</title><link>https://duynht.github.io/publication/protein_classes/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/protein_classes/</guid><description>&lt;p>This paper presents the methods that have participated in the SHREC 2021 contest on retrieval and classification of protein surfaces on the basis of their geometry and physicochemical properties.&lt;/p></description></item><item><title>SHREC 2021: Surface-based Protein Domains Retrieval (3DOR 2021)</title><link>https://duynht.github.io/publication/protein_domains/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/protein_domains/</guid><description>&lt;p>This paper assesses the ability of five methods to retrieve similar protein surfaces, using either their shape only (3D meshes), or their shape and the electrostatic potential at their surface, an important surface property.&lt;/p></description></item><item><title>Surface-based protein domains retrieval methods from a SHREC2021 challenge (JMGM Vol. 111)</title><link>https://duynht.github.io/publication/protein_domains_journal/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/protein_domains_journal/</guid><description>&lt;p>Five different groups participated in this contest using the shape-only dataset, and one group extended its pre-existing method to handle the electrostatic potential. Our comparative study reveals both the ability of the methods to detect related proteins and their difficulties to distinguish between highly related proteins. Our study allows also to analyze the putative influence of electrostatic information in addition to the one of protein shapes alone.&lt;/p></description></item><item><title>Towards a Gratifying Interactive Modality for Smart Environments based on Ubiquitous Sensing (BSc. Thesis)</title><link>https://duynht.github.io/publication/accel_watch/</link><pubDate>Sat, 28 Aug 2021 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/accel_watch/</guid><description>&lt;p>In this thesis, we set forth to extend this line of research for intuitive, effortless, and enjoyable computer interaction by employing a natural everyday-carry object &amp;ndash; the smartwatch.&lt;/p></description></item><item><title>HCMUS at MediaEval 2020: Image-Text Fusion for Automatic News-Images Re-Matching (MediaEval 2020)</title><link>https://duynht.github.io/publication/image_text/</link><pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/image_text/</guid><description>&lt;p>We propose three multi-modal methods for mapping text and images of news articles to the shared space in order to perform efficient cross-retrieval.&lt;/p></description></item><item><title>Recognizing Families through Images with Pretrained Encoder (FG 2020)</title><link>https://duynht.github.io/publication/kinship/</link><pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/kinship/</guid><description>&lt;p>We employ 3 methods, FaceNet, Siamese VGGFace, and a combination of FaceNet and VGG-Face models as feature extractors, to achieve the 9th standing for kinship verification and the 5th standing for kinship retrieval in the Recognizing Family in The Wild 2020 competition.&lt;/p></description></item><item><title>Towards a Robust WiFi-based Fall Detection with Adversarial Data Augmentation (CISS 2020)</title><link>https://duynht.github.io/publication/wifi/</link><pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate><guid>https://duynht.github.io/publication/wifi/</guid><description>&lt;p>This paper investigates a method of generalization through adversarial data augmentation.&lt;/p></description></item></channel></rss>